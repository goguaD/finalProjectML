# finalProjectML

მონაცემები:
train.csv: ყოველკვირეული გაყიდვების მონაცემები 2010-დან to 2012-მდე.

test.csv: სატესტო მონაცემები.

features.csv: შემდეგი დამატებითი ინფორმაცია: ტემპერატურა, ბენზინის ფასი, CPI(The Consumer Price Index), უმუშევრობა, ფასდაკლებები, დღესასწაულები

stores.csv: დამატებითი ინფორმაცია ყველა მაღაზიაზე: მაღაზიის ტიპები და ზომები.

sampleSubmission.csv: საბმიშენის ფორმატი.

## Exploratory Data Analysis (EDA)
<img width="1243" height="496" alt="image" src="https://github.com/user-attachments/assets/fa3ff40c-afa2-463d-ad21-7a79c963de20" />

### Key Findings and Patterns

#### 1. გაყიდვების განაწილება
- **სეზონური პატერნები**: ცალსახა სეზონური პიკები ყველაზე დიდ გავლენას ახდენს ყოველკვირეულ გაყიდვებზე
- **დღესასწაულების სეზონური გავლენა**: ნოემბერი-დეკემბრის პერიოდში ცალსახა პიკს ვხედავთ
- **ყოველწლიური ტრენდები**: გაყიდვები შუა წელში მცირდება და წლის ბოლოს, არდადეგების პერიოდში იზრდება
<img width="1243" height="496" alt="image" src="https://github.com/user-attachments/assets/05bd2140-198f-4264-91a8-a0c1c203b850" />

#### 2. მაღაზიების პერფორმანსი
- **მაღაზიის ტიპები**: A ტიპის მაღაზიები საშუალოდ ყველაზე დიდ შემოსავალს ნახულობენ
- **მაღაზიების ზომასთან კორელაცია**: დიდი მაღაზიები მეტ შემოსავალს იღებენ, თუმცა შედარებით ნაკლები კორელაცია აქვთ გაყიდვების ზრდასთან
<img width="577" height="459" alt="image" src="https://github.com/user-attachments/assets/2b8f97bc-caee-4007-818b-b6959f8d4344" />

<img width="904" height="556" alt="image" src="https://github.com/user-attachments/assets/6a982b29-4635-49b0-95cb-798b28c77b6f" />

#### 3. დეპარტამენტების ტრენდები
- **გაყიდვების მაღალი კონცენტრაცია**: რამდენიმე დეპარტამენტი დომინირებს გაყიდვების მოცულობით
- **Department Variability**: Activity across departments varies significantly and shows seasonal patterns
- **Performance Patterns**: Different departments exhibit unique seasonal behaviors and sales cycles
<img width="998" height="560" alt="image" src="https://github.com/user-attachments/assets/1d75d591-832b-4460-8e46-3904e1db2a24" />

#### 4. Holiday and Markdown Effects
- **დღესასწაულების გავლენა**: დღესასწაულებს დიდი გავლენა აქვს გაყიდვებზე
- **ფასდაკლებების გავლენა**: ფასდაკლებებს დადებითი გავლენა აქვს ზოგ კვირაში გაყიდვებზე
- **სეზონური პიკები**: მნიშვნელოვანი დღესასწაულები გაყოდვების პიკებს ქმნიან 
<img width="724" height="621" alt="image" src="https://github.com/user-attachments/assets/da02aa87-b546-40e4-a145-5a4465aeccb2" />
<img width="577" height="487" alt="image" src="https://github.com/user-attachments/assets/79911c33-22b1-407d-b1e6-dcf2660402ae" />

#### 5. ეკონომიკური ფაქტორების ანალიზო
- **ნაკლები გავლენა**: CPI, საწვავის ფასს, და უმუშევრობას მინიმალურიეფექტი აქვს
- **კორელაზია**: ეკონომიკურ ინდიკატორებს ძალიან სუსტი კორელაცია აქვთ ყოველკვირეულ გაყიდვებთან
- **ტემპერატურა**: ექსტრემალურ მონაცემებზე საშუალო კორელაცია აქვს


#### 7. Time Series Characteristics
- **ავტოკორელაცია**: ავტოკორელაციის პატერნები იმას მიუთითებს, რომ უახლოესი გაყიდვები მნიშვნელოვანია პროგნოზირებისთვის, ამიტომ გამოსადეგი იქნება ლეგ ფიჩერები. 
- **სეზონურობა**: ცალსახა კვირეული და თვიური პატერნებია დატასეტში
<img width="577" height="467" alt="image" src="https://github.com/user-attachments/assets/87a5e0ce-b77c-4caf-a684-a81b829aec3c" />
<img width="623" height="464" alt="image" src="https://github.com/user-attachments/assets/b420cc42-d0c9-49c2-a171-38183b492a71" />

#### 8. Feature Correlation Analysis
- **აღსანიშნავი კორელაციები**: მაღაზიის ტიპი,ზომა, და დღესასწაულები
- **სუსტი კორელაციები**: ეკონომიკური ინდიკატორები (CPI, უმუშევრობა, საწვავის ფასი) 
- **ფასდაკლების ეფექტი**: სხვადასხვა ფასდაკლებების ტიპები სხვაასხვა კორელაციაში მოდიან გაყოდვებთან
<img width="1983" height="1226" alt="image" src="https://github.com/user-attachments/assets/210543d8-682c-44ce-85ec-0677dd119ade" />

# Deep Learning

## N-BEATS

• **მოდელის სპეციფიკა:** N-BEATS მოდელი თითოეული (store, dept) წყვილისთვის ინდივიდუალურად იქმნება, რადგან თითოეულს უნიკალური გაყიდვების ისტორიული პატერნი გააჩნია. ეს უზრუნველყოფს მაღალ სიზუსტეს თითოეული დროითი სერიისთვის.

• **მონაცემთა დამუშავება:** N-BEATS არქიტექტურა არ საჭიროებს კომპლექსურ feature engineering-ს. მოდელი მუშაობს პირდაპირ `weekly_sales`-ის ისტორიულ მონაცემებზე. მთავარი მოთხოვნაა მონაცემების ქრონოლოგიური სიზუსტე, რისთვისაც ვიყენებთ **ტემპორალურ გაყოფას (Temporal Split)**.

• **მონაცემების გაყოფა:** test/validation - 70/30 (ქრონოლოგიურად).

### არქიტექტურა და პარამეტრები

N-BEATS-ის არქიტექტურა დაფუძნებულია სტეკების (stacks) იდეაზე, სადაც თითოეული სტეკი სწავლობს მონაცემების კონკრეტულ კომპონენტს (ტრენდი, სეზონურობა).

| პარამეტრი | მნიშვნელობა | აღწერა |
|---|---|---|
| **`stack_types`** | `['trend', 'seasonality', 'generic']` | მოდელი შედგება 3 ძირითადი სტეკისგან: ტრენდის, სეზონურობის და ზოგადი პატერნების ამოსაცნობად. |
| **`input_size` (Backcast)** | 24 | მოდელი იყენებს ბოლო 24 კვირის მონაცემს მომავლის პროგნოზირებისთვის. |
| **`h` (Forecast)** | 4 | მოდელის მიზანია მომდევნო 4 კვირის გაყიდვების პროგნოზირება. |
| **`batch_size`** | 128 | ერთ ჯერზე მუშავდება 128 დროითი სერია, რაც აჩქარებს ტრენინგს და ასტაბილურებს გრადიენტებს. |
| **`early_stop_patience`** | 5 ეპოქა | ტრენინგი ავტომატურად ჩერდება, თუ ვალიდაციის ცდომილება 5 ეპოქის განმავლობაში არ უმჯობესდება. |
| **`scaler_type`** | `StandardScaler` / `RobustScaler` | მონაცემების სკალირება ხდება ნორმალიზაციისთვის. |
| **`learning_rate`** | 0.001 | სწავლების სიჩქარე, რომელიც კონტროლდება `ReduceLROnPlateau` სქემით. |
| **`AMP (Mixed Precision)`** | `True` | გამოიყენება ავტომატური შერეული სიზუსტე, რაც 2-ჯერ აჩქარებს ტრენინგს GPU-ზე. |

---

### Hyperparameter Tuning და შედეგები

ჩატარდა ჰიპერპარამეტრების ოპტიმიზაცია საუკეთესო შედეგის მისაღებად:

• **Input Size-ის გაზრდა:** გავზარდეთ `input_size`, რათა მოდელმა მეტი ისტორიული კონტექსტი გაითვალისწინოს.

• **Batch Size-ის ოპტიმიზაცია:** შევარჩიეთ ოპტიმალური `batch_size` სტაბილური და სწრაფი სწავლისთვის.

• **Scaler-ის შერჩევა:** `weekly_sales` მონაცემები შეიცავს ბევრ outlier-ს. `RobustScaler`-მა აჩვენა საუკეთესო შედეგი, რადგან ის ნაკლებად მგრძნობიარეა ექსტრემალური მნიშვნელობების მიმართ, `StandardScaler`-თან შედარებით.

#### საბოლოო შედეგი:

**Validation WMAE: 1648.15**

---

### შედეგების ვიზუალიზაცია

ქვემოთ მოცემულია მოდელის მუშაობის ამსახველი გრაფიკები, რომლებიც დაგენერირდა `Correct_N_BEATS.ipynb` ფაილში.

**1. ტრენინგის პროგრესი (Train vs Validation Loss)**
*გრაფიკი გვიჩვენებს, თუ როგორ მცირდებოდა ცდომილება ტრენინგის პროცესში, რაც მიუთითებს წარმატებულ სწავლაზე.*

**2. პროგნოზის შედარება რეალურ მონაცემებთან (Sample Forecast)**
*აქ ჩანს, თუ რამდენად ახლოსაა მოდელის პროგნოზი რეალურ გაყიდვებთან კონკრეტული მაგალითისთვის.*

**3. პროგნოზებისა და რეალური გაყიდვების Scatter Plot**
*იდეალურ შემთხვევაში, წერტილები უნდა განლაგდეს დიაგონალურ ხაზზე, რაც მაღალ სიზუსტეზე მიუთითებს.*
<img width="551" height="177" alt="Screenshot 2025-08-01 at 3 06 15 AM" src="https://github.com/user-attachments/assets/7d8ff74d-aedd-4d72-85c6-1a9ac08c92e4" />

---

## DLinear

• DLinear არის მარტივი, მაგრამ ეფექტური ღრმა სწავლების მოდელი, რომელიც იყენებს ერთ წრფივ (Linear) ფენას პროგნოზირებისთვის.

• N-BEATS-ისგან განსხვავებით, ეს DLinear მოდელი იყენებს დამატებით მახასიათებლებს (features) როგორიცაა 'Temperature', 'Fuel_Price', 'CPI', 'Unemployment', რაც მას საშუალებას აძლევს გაითვალისწინოს გარე ფაქტორები.

• test/validation - 80/20 (shuffle=False, რაც ინარჩუნებს დროით თანმიმდევრობას).

| პარამეტრი | მნიშვნელობა | აღწერა |
|----------|-------------|--------|
| input_len | 12 | რამდენი წარსული დროის ნაბიჯი (კვირა) გამოიყენება პროგნოზისთვის. |
| output_len | 1 | რამდენი მომავალი დროის ნაბიჯის პროგნოზირება ხდება (1 კვირა). |
| batch_size | 32 | ერთ ჯერზე დასამუშავებელი მონაცემების რაოდენობა. |
| learning_rate | 5e-4 | სწავლების სიჩქარე, რომელიც განსაზღვრავს რამდენად სწრაფად სწავლობს მოდელი. |
| n_features | 12 | მოდელში გამოყენებული დამატებითი მახასიათებლების რაოდენობა. |

**Validation WMAE: 3208.87**

### მოდელის შეფასება

• **სიმარტივე:** 
DLinear-ის მთავარი უპირატესობა მისი სიმარტივეა. ის სწრაფია და მარტივი გასაგები.

• **დამატებითი მახასიათებლები:** გარე ფაქტორების გათვალისწინება პოტენციურად აუმჯობესებს პროგნოზს.

• **შედეგი:** მიუხედავად სიმარტივისა, მისი WMAE მნიშვნელოვნად მაღალია (3208.87) N-BEATS-თან შედარებით (1648.15), რაც აჩვენებს, რომ N-BEATS-ის რთული არქიტექტურა ბევრად უკეთ უმკლავდება ამ კონკრეტულ ამოცანას.

## მოდელების შედარება: Deep Learning vs. Classical ML vs. Time Series

| თვისება | Deep Learning (N-BEATS, DLinear) | კლასიკური ML (XGBoost, LightGBM) | Time Series მოდელები (ARIMA, SARIMA) |
|---|---|---|---|
| **მონაცემთა ტიპი** | მუშაობს როგორც დროით, ისე ზოგად ტაბულურ მონაცემებზე. | ძირითადად ტაბულურ მონაცემებზე; დროითი ასპექტი მოითხოვს ხელით დამუშავებას. | მხოლოდ დროით სერიებზე (Univariate/Multivariate). |
| **Feature Engineering** | **ავტომატური:** თავად სწავლობს მახასიათებლებს მონაცემებიდან. | **ხელით:** საჭიროებს მახასიათებლების შექმნას (მაგ. lags, moving averages). | **არ სჭირდება:** მუშაობს პირდაპირ დროითი სერიის სტატისტიკურ თვისებებზე (p, d, q). |
| **მონაცემების გაყოფა** | **ტემპორალური (Temporal Split):** ინარჩუნებს დროით თანმიმდევრობას (მაგ. 70%-30%). | **შემთხვევითი (Random Split):** ხშირად გამოიყენება, თუ დროითი ასპექტი იგნორირებულია. | **ტემპორალური:** ყოველთვის გამოიყენება დროითი თანმიმდევრობის შესანარჩუნებლად. |
| **არაწრფივობა** | **მაღალი:** ღრმა ფენების წყალობით, შეუძლიათ რთული, არაწრფივი პატერნების შესწავლა. | **შეზღუდული:** ხეზე დაფუძნებული მოდელები მონაცემებს მარტივი წესებით ყოფენ. | **ძირითადად წრფივი:** ARIMA ეფუძნება წრფივ კავშირებს. |
| **გარე ფაქტორები** | **მარტივი ინტეგრაცია:** ადვილად ითვალისწინებს დამატებით მახასიათებლებს (features). | **მარტივი ინტეგრაცია:** ითვალისწინებს დამატებით მახასიათებლებს. | **შეზღუდული:** SARIMAX-ს შეუძლია, მაგრამ ინტეგრაცია უფრო რთულია. |
| **ინტერპრეტაცია** | **რთული ("შავი ყუთი"):** რთულია იმის გაგება, თუ როგორ იღებს გადაწყვეტილებას. | **შედარებით მარტივი:** ხეების ლოგიკა ან მახასიათებლების მნიშვნელოვნება გასაგებია. | **ძალიან მარტივი:** პარამეტრებს (p, d, q) და კომპონენტებს (ტრენდი, სეზონი) აქვთ მკაფიო სტატისტიკური ახსნა. |

მოკლედ, **Deep Learning** მოდელები გამოირჩევიან მოქნილობითა და რთული პატერნების ავტომატურად შესწავლის უნარით. **კლასიკური ML** მოდელები ეფექტურია ტაბულურ მონაცემებზე და მოითხოვს მეტ ხელით ჩარევას. **Time Series** მოდელები კი სპეციალიზებული და მაღალ ინტერპრეტირებადია, თუმცა ნაკლებად მოქნილი.

