{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "import json\n",
        "import zipfile\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "SWCTOVXUN5rq"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Mounting Google Drive...\")\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A5i2hPMCN57W",
        "outputId": "28355e46-8522-4423-d4ae-917575ce11a9"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounting Google Drive...\n",
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        },
        "id": "KWohnufbN-Av",
        "outputId": "a34f267b-58f6-4d4b-fde2-6676f86335ba"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-26d8e4c7-eead-4614-975f-2ad206db7541\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-26d8e4c7-eead-4614-975f-2ad206db7541\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'kaggle.json': b'{\"username\":\"ditogogua\",\"key\":\"65a423eed3ea99d51a9c7348b802e85b\"}'}"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "VQ_ZVE_iOCm1"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle competitions list | head -5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZwwyqDgtOFHw",
        "outputId": "88eb6a1a-a27b-43e2-ca82-b4a440529189"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ref                                                                              deadline             category                reward  teamCount  userHasEntered  \n",
            "-------------------------------------------------------------------------------  -------------------  ---------------  -------------  ---------  --------------  \n",
            "https://www.kaggle.com/competitions/arc-prize-2025                               2025-11-03 23:59:00  Featured         1,000,000 Usd        640           False  \n",
            "https://www.kaggle.com/competitions/google-gemma-3n-hackathon                    2025-08-06 23:59:00  Featured           150,000 Usd          0           False  \n",
            "https://www.kaggle.com/competitions/make-data-count-finding-data-references      2025-09-09 23:59:00  Research           100,000 Usd        560           False  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle competitions download -c walmart-recruiting-store-sales-forecasting"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GcCoC5OnOPHT",
        "outputId": "cd808952-3a0e-43bc-cf1c-85ff4c52efe5"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading walmart-recruiting-store-sales-forecasting.zip to /content\n",
            "\r  0% 0.00/2.70M [00:00<?, ?B/s]\n",
            "\r100% 2.70M/2.70M [00:00<00:00, 796MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with zipfile.ZipFile('walmart-recruiting-store-sales-forecasting.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('walmart_data')\n",
        "\n",
        "print(\"Extracted files:\")\n",
        "for root, dirs, files in os.walk('walmart_data'):\n",
        "    for file in files:\n",
        "        print(os.path.join(root, file))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1tbsccP2OSFw",
        "outputId": "dd1ad838-90d7-4af4-9968-50bf55248a85"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted files:\n",
            "walmart_data/stores.csv\n",
            "walmart_data/sampleSubmission.csv.zip\n",
            "walmart_data/train.csv.zip\n",
            "walmart_data/features.csv.zip\n",
            "walmart_data/test.csv.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nExtracting individual CSV files...\")\n",
        "csv_files = ['train.csv.zip', 'test.csv.zip', 'features.csv.zip', 'stores.csv', 'sampleSubmission.csv.zip']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JUtK1IG63BzH",
        "outputId": "a0cb7179-4da0-4a9e-f00a-7b1c4d09c6c8"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Extracting individual CSV files...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for file in csv_files:\n",
        "    file_path = os.path.join('walmart_data', file)\n",
        "    if os.path.exists(file_path) and file.endswith('.zip'):\n",
        "        print(f\"Extracting {file}...\")\n",
        "        with zipfile.ZipFile(file_path, 'r') as zip_ref:\n",
        "            zip_ref.extractall('walmart_data')\n",
        "    elif os.path.exists(file_path):\n",
        "        print(f\"{file} already extracted or not zipped\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7q660IxI3Mfx",
        "outputId": "901ad7dc-ab89-4d1f-8d16-08f9ac8f5162"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting train.csv.zip...\n",
            "Extracting test.csv.zip...\n",
            "Extracting features.csv.zip...\n",
            "stores.csv already extracted or not zipped\n",
            "Extracting sampleSubmission.csv.zip...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nFinal extracted files:\")\n",
        "for root, dirs, files in os.walk('walmart_data'):\n",
        "    for file in files:\n",
        "        if file.endswith('.csv'):\n",
        "            print(os.path.join(root, file))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FmJNE3ul3Rva",
        "outputId": "ba661063-e399-4d39-c1de-e0f2f590c788"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Final extracted files:\n",
            "walmart_data/train.csv\n",
            "walmart_data/sampleSubmission.csv\n",
            "walmart_data/stores.csv\n",
            "walmart_data/test.csv\n",
            "walmart_data/features.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install statsmodels\n",
        "\n",
        "from datetime import datetime\n",
        "from statsmodels.tsa.arima.model import ARIMA\n",
        "from statsmodels.tsa.stattools import adfuller\n",
        "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
        "from statsmodels.tsa.seasonal import seasonal_decompose\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from itertools import product"
      ],
      "metadata": {
        "id": "yJz6qGCBcwHg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7454677d-1c74-4391-b06a-89023a307410"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: statsmodels in /usr/local/lib/python3.11/dist-packages (0.14.5)\n",
            "Requirement already satisfied: numpy<3,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from statsmodels) (2.0.2)\n",
            "Requirement already satisfied: scipy!=1.9.2,>=1.8 in /usr/local/lib/python3.11/dist-packages (from statsmodels) (1.15.3)\n",
            "Requirement already satisfied: pandas!=2.1.0,>=1.4 in /usr/local/lib/python3.11/dist-packages (from statsmodels) (2.2.2)\n",
            "Requirement already satisfied: patsy>=0.5.6 in /usr/local/lib/python3.11/dist-packages (from statsmodels) (1.0.1)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.11/dist-packages (from statsmodels) (24.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas!=2.1.0,>=1.4->statsmodels) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.style.use('default')\n",
        "sns.set_palette(\"husl\")"
      ],
      "metadata": {
        "id": "Aldz0pS91D9Q"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_wmae(y_true, y_pred, is_holiday, holiday_weight=5):\n",
        "    weights = np.where(is_holiday, holiday_weight, 1)\n",
        "    denom = np.sum(weights)\n",
        "    if denom == 0:\n",
        "        return np.nan\n",
        "    return np.sum(weights * np.abs(y_true - y_pred)) / denom\n"
      ],
      "metadata": {
        "id": "8bW5Gu624R3s"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_y_true, total_y_pred, total_is_holiday = [], [], []\n",
        "\n",
        "val_weeks = int(len(walmart_arima.train_data) * 0.1)\n",
        "val_data = walmart_arima.train_data.tail(val_weeks)\n",
        "\n",
        "grouped = val_data.groupby(['Store', 'Dept'])\n",
        "\n",
        "for (store, dept), group in grouped:\n",
        "    group = group.sort_values('Date')\n",
        "    ts = group.set_index('Date')['Weekly_Sales'].resample('W').sum().fillna(0)\n",
        "\n",
        "    if len(ts) < 20:\n",
        "        continue\n",
        "\n",
        "    model = walmart_arima.simple_arima_fit(ts)\n",
        "    if model is None:\n",
        "        continue\n",
        "\n",
        "    steps = len(ts)\n",
        "    try:\n",
        "        forecast, _ = walmart_arima.forecast_sales(model, steps=steps, title=f\"Validation ({store}-{dept})\")\n",
        "    except:\n",
        "        continue\n",
        "\n",
        "    if len(forecast) != len(ts):\n",
        "        continue\n",
        "\n",
        "    total_y_true.extend(ts.values)\n",
        "    total_y_pred.extend(forecast.values)\n",
        "\n",
        "    holiday_series = group.groupby('Date')['IsHoliday'].max().resample('W').max().reindex(ts.index).fillna(False).astype(bool)\n",
        "    total_is_holiday.extend(holiday_series.values)\n",
        "\n",
        "y_true = np.array(total_y_true)\n",
        "y_pred = np.array(total_y_pred)\n",
        "is_holiday = np.array(total_is_holiday)\n",
        "\n",
        "valid = ~np.isnan(y_true) & ~np.isnan(y_pred)\n",
        "if valid.sum() == 0:\n",
        "    print(\"❌ No valid data to compute WMAE\")\n",
        "else:\n",
        "    wmae = compute_wmae(y_true[valid], y_pred[valid], is_holiday[valid])\n",
        "    print(f\"✅ Local Validation WMAE: {wmae:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nCut59rE9BW3",
        "outputId": "fe4e2a46-65ec-4774-e61a-62f09d39390a"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Generating forecasts for Validation (40-85)...\n",
            "\n",
            "Generating forecasts for Validation (40-87)...\n",
            "\n",
            "Generating forecasts for Validation (40-90)...\n",
            "\n",
            "Generating forecasts for Validation (40-91)...\n",
            "\n",
            "Generating forecasts for Validation (40-92)...\n",
            "\n",
            "Generating forecasts for Validation (40-93)...\n",
            "\n",
            "Generating forecasts for Validation (40-94)...\n",
            "\n",
            "Generating forecasts for Validation (40-95)...\n",
            "\n",
            "Generating forecasts for Validation (40-96)...\n",
            "\n",
            "Generating forecasts for Validation (40-97)...\n",
            "\n",
            "Generating forecasts for Validation (40-98)...\n",
            "\n",
            "Generating forecasts for Validation (40-99)...\n",
            "\n",
            "Generating forecasts for Validation (41-1)...\n",
            "\n",
            "Generating forecasts for Validation (41-2)...\n",
            "\n",
            "Generating forecasts for Validation (41-3)...\n",
            "\n",
            "Generating forecasts for Validation (41-4)...\n",
            "\n",
            "Generating forecasts for Validation (41-5)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/statsmodels/base/model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Generating forecasts for Validation (41-6)...\n",
            "\n",
            "Generating forecasts for Validation (41-7)...\n",
            "\n",
            "Generating forecasts for Validation (41-8)...\n",
            "\n",
            "Generating forecasts for Validation (41-9)...\n",
            "\n",
            "Generating forecasts for Validation (41-10)...\n",
            "\n",
            "Generating forecasts for Validation (41-11)...\n",
            "\n",
            "Generating forecasts for Validation (41-12)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/statsmodels/base/model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Generating forecasts for Validation (41-13)...\n",
            "\n",
            "Generating forecasts for Validation (41-14)...\n",
            "\n",
            "Generating forecasts for Validation (41-16)...\n",
            "\n",
            "Generating forecasts for Validation (41-17)...\n",
            "\n",
            "Generating forecasts for Validation (41-18)...\n",
            "\n",
            "Generating forecasts for Validation (41-19)...\n",
            "\n",
            "Generating forecasts for Validation (41-20)...\n",
            "\n",
            "Generating forecasts for Validation (41-21)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/statsmodels/base/model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Generating forecasts for Validation (41-22)...\n",
            "\n",
            "Generating forecasts for Validation (41-23)...\n",
            "\n",
            "Generating forecasts for Validation (41-24)...\n",
            "\n",
            "Generating forecasts for Validation (41-25)...\n",
            "\n",
            "Generating forecasts for Validation (41-26)...\n",
            "\n",
            "Generating forecasts for Validation (41-27)...\n",
            "\n",
            "Generating forecasts for Validation (41-28)...\n",
            "\n",
            "Generating forecasts for Validation (41-29)...\n",
            "\n",
            "Generating forecasts for Validation (41-30)...\n",
            "\n",
            "Generating forecasts for Validation (41-31)...\n",
            "\n",
            "Generating forecasts for Validation (41-32)...\n",
            "\n",
            "Generating forecasts for Validation (41-33)...\n",
            "\n",
            "Generating forecasts for Validation (41-34)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/statsmodels/base/model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Generating forecasts for Validation (41-35)...\n",
            "\n",
            "Generating forecasts for Validation (41-36)...\n",
            "\n",
            "Generating forecasts for Validation (41-38)...\n",
            "\n",
            "Generating forecasts for Validation (41-40)...\n",
            "\n",
            "Generating forecasts for Validation (41-41)...\n",
            "\n",
            "Generating forecasts for Validation (41-42)...\n",
            "\n",
            "Generating forecasts for Validation (41-44)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/statsmodels/base/model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Generating forecasts for Validation (41-45)...\n",
            "\n",
            "Generating forecasts for Validation (41-46)...\n",
            "\n",
            "Generating forecasts for Validation (41-47)...\n",
            "\n",
            "Generating forecasts for Validation (41-48)...\n",
            "\n",
            "Generating forecasts for Validation (41-49)...\n",
            "\n",
            "Generating forecasts for Validation (41-51)...\n",
            "\n",
            "Generating forecasts for Validation (41-52)...\n",
            "\n",
            "Generating forecasts for Validation (41-54)...\n",
            "\n",
            "Generating forecasts for Validation (41-55)...\n",
            "\n",
            "Generating forecasts for Validation (41-56)...\n",
            "\n",
            "Generating forecasts for Validation (41-58)...\n",
            "\n",
            "Generating forecasts for Validation (41-59)...\n",
            "\n",
            "Generating forecasts for Validation (41-60)...\n",
            "\n",
            "Generating forecasts for Validation (41-67)...\n",
            "\n",
            "Generating forecasts for Validation (41-71)...\n",
            "\n",
            "Generating forecasts for Validation (41-72)...\n",
            "\n",
            "Generating forecasts for Validation (41-74)...\n",
            "\n",
            "Generating forecasts for Validation (41-77)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/statsmodels/base/model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Generating forecasts for Validation (41-78)...\n",
            "\n",
            "Generating forecasts for Validation (41-79)...\n",
            "\n",
            "Generating forecasts for Validation (41-80)...\n",
            "\n",
            "Generating forecasts for Validation (41-81)...\n",
            "\n",
            "Generating forecasts for Validation (41-82)...\n",
            "\n",
            "Generating forecasts for Validation (41-83)...\n",
            "\n",
            "Generating forecasts for Validation (41-85)...\n",
            "\n",
            "Generating forecasts for Validation (41-87)...\n",
            "\n",
            "Generating forecasts for Validation (41-90)...\n",
            "\n",
            "Generating forecasts for Validation (41-91)...\n",
            "\n",
            "Generating forecasts for Validation (41-92)...\n",
            "\n",
            "Generating forecasts for Validation (41-93)...\n",
            "\n",
            "Generating forecasts for Validation (41-94)...\n",
            "\n",
            "Generating forecasts for Validation (41-95)...\n",
            "\n",
            "Generating forecasts for Validation (41-96)...\n",
            "\n",
            "Generating forecasts for Validation (41-97)...\n",
            "\n",
            "Generating forecasts for Validation (41-98)...\n",
            "\n",
            "Generating forecasts for Validation (41-99)...\n",
            "\n",
            "Generating forecasts for Validation (42-1)...\n",
            "\n",
            "Generating forecasts for Validation (42-2)...\n",
            "\n",
            "Generating forecasts for Validation (42-3)...\n",
            "\n",
            "Generating forecasts for Validation (42-4)...\n",
            "\n",
            "Generating forecasts for Validation (42-5)...\n",
            "\n",
            "Generating forecasts for Validation (42-7)...\n",
            "\n",
            "Generating forecasts for Validation (42-8)...\n",
            "\n",
            "Generating forecasts for Validation (42-9)...\n",
            "\n",
            "Generating forecasts for Validation (42-10)...\n",
            "\n",
            "Generating forecasts for Validation (42-11)...\n",
            "\n",
            "Generating forecasts for Validation (42-12)...\n",
            "\n",
            "Generating forecasts for Validation (42-13)...\n",
            "\n",
            "Generating forecasts for Validation (42-14)...\n",
            "\n",
            "Generating forecasts for Validation (42-16)...\n",
            "\n",
            "Generating forecasts for Validation (42-17)...\n",
            "\n",
            "Generating forecasts for Validation (42-18)...\n",
            "\n",
            "Generating forecasts for Validation (42-20)...\n",
            "\n",
            "Generating forecasts for Validation (42-21)...\n",
            "\n",
            "Generating forecasts for Validation (42-22)...\n",
            "\n",
            "Generating forecasts for Validation (42-23)...\n",
            "\n",
            "Generating forecasts for Validation (42-25)...\n",
            "\n",
            "Generating forecasts for Validation (42-26)...\n",
            "\n",
            "Generating forecasts for Validation (42-27)...\n",
            "\n",
            "Generating forecasts for Validation (42-28)...\n",
            "\n",
            "Generating forecasts for Validation (42-31)...\n",
            "\n",
            "Generating forecasts for Validation (42-32)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/statsmodels/base/model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Generating forecasts for Validation (42-33)...\n",
            "\n",
            "Generating forecasts for Validation (42-38)...\n",
            "\n",
            "Generating forecasts for Validation (42-40)...\n",
            "\n",
            "Generating forecasts for Validation (42-41)...\n",
            "\n",
            "Generating forecasts for Validation (42-42)...\n",
            "\n",
            "Generating forecasts for Validation (42-44)...\n",
            "\n",
            "Generating forecasts for Validation (42-46)...\n",
            "\n",
            "Generating forecasts for Validation (42-49)...\n",
            "\n",
            "Generating forecasts for Validation (42-52)...\n",
            "\n",
            "Generating forecasts for Validation (42-55)...\n",
            "\n",
            "Generating forecasts for Validation (42-56)...\n",
            "\n",
            "Generating forecasts for Validation (42-59)...\n",
            "\n",
            "Generating forecasts for Validation (42-60)...\n",
            "\n",
            "Generating forecasts for Validation (42-67)...\n",
            "\n",
            "Generating forecasts for Validation (42-71)...\n",
            "\n",
            "Generating forecasts for Validation (42-72)...\n",
            "\n",
            "Generating forecasts for Validation (42-74)...\n",
            "\n",
            "Generating forecasts for Validation (42-79)...\n",
            "\n",
            "Generating forecasts for Validation (42-80)...\n",
            "\n",
            "Generating forecasts for Validation (42-81)...\n",
            "\n",
            "Generating forecasts for Validation (42-82)...\n",
            "\n",
            "Generating forecasts for Validation (42-83)...\n",
            "\n",
            "Generating forecasts for Validation (42-85)...\n",
            "\n",
            "Generating forecasts for Validation (42-87)...\n",
            "\n",
            "Generating forecasts for Validation (42-90)...\n",
            "\n",
            "Generating forecasts for Validation (42-91)...\n",
            "\n",
            "Generating forecasts for Validation (42-92)...\n",
            "\n",
            "Generating forecasts for Validation (42-93)...\n",
            "\n",
            "Generating forecasts for Validation (42-94)...\n",
            "\n",
            "Generating forecasts for Validation (42-95)...\n",
            "\n",
            "Generating forecasts for Validation (42-96)...\n",
            "\n",
            "Generating forecasts for Validation (42-97)...\n",
            "\n",
            "Generating forecasts for Validation (42-98)...\n",
            "\n",
            "Generating forecasts for Validation (43-1)...\n",
            "\n",
            "Generating forecasts for Validation (43-2)...\n",
            "\n",
            "Generating forecasts for Validation (43-3)...\n",
            "\n",
            "Generating forecasts for Validation (43-4)...\n",
            "\n",
            "Generating forecasts for Validation (43-5)...\n",
            "\n",
            "Generating forecasts for Validation (43-6)...\n",
            "\n",
            "Generating forecasts for Validation (43-7)...\n",
            "\n",
            "Generating forecasts for Validation (43-8)...\n",
            "\n",
            "Generating forecasts for Validation (43-9)...\n",
            "\n",
            "Generating forecasts for Validation (43-10)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/statsmodels/base/model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Generating forecasts for Validation (43-11)...\n",
            "\n",
            "Generating forecasts for Validation (43-12)...\n",
            "\n",
            "Generating forecasts for Validation (43-13)...\n",
            "\n",
            "Generating forecasts for Validation (43-14)...\n",
            "\n",
            "Generating forecasts for Validation (43-16)...\n",
            "\n",
            "Generating forecasts for Validation (43-17)...\n",
            "\n",
            "Generating forecasts for Validation (43-18)...\n",
            "\n",
            "Generating forecasts for Validation (43-20)...\n",
            "\n",
            "Generating forecasts for Validation (43-21)...\n",
            "\n",
            "Generating forecasts for Validation (43-22)...\n",
            "\n",
            "Generating forecasts for Validation (43-23)...\n",
            "\n",
            "Generating forecasts for Validation (43-24)...\n",
            "\n",
            "Generating forecasts for Validation (43-25)...\n",
            "\n",
            "Generating forecasts for Validation (43-26)...\n",
            "\n",
            "Generating forecasts for Validation (43-27)...\n",
            "\n",
            "Generating forecasts for Validation (43-28)...\n",
            "\n",
            "Generating forecasts for Validation (43-31)...\n",
            "\n",
            "Generating forecasts for Validation (43-32)...\n",
            "\n",
            "Generating forecasts for Validation (43-33)...\n",
            "\n",
            "Generating forecasts for Validation (43-38)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/statsmodels/base/model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Generating forecasts for Validation (43-40)...\n",
            "\n",
            "Generating forecasts for Validation (43-42)...\n",
            "\n",
            "Generating forecasts for Validation (43-44)...\n",
            "\n",
            "Generating forecasts for Validation (43-46)...\n",
            "\n",
            "Generating forecasts for Validation (43-49)...\n",
            "\n",
            "Generating forecasts for Validation (43-52)...\n",
            "\n",
            "Generating forecasts for Validation (43-56)...\n",
            "\n",
            "Generating forecasts for Validation (43-59)...\n",
            "\n",
            "Generating forecasts for Validation (43-60)...\n",
            "\n",
            "Generating forecasts for Validation (43-67)...\n",
            "\n",
            "Generating forecasts for Validation (43-71)...\n",
            "\n",
            "Generating forecasts for Validation (43-72)...\n",
            "\n",
            "Generating forecasts for Validation (43-74)...\n",
            "\n",
            "Generating forecasts for Validation (43-79)...\n",
            "\n",
            "Generating forecasts for Validation (43-80)...\n",
            "\n",
            "Generating forecasts for Validation (43-81)...\n",
            "\n",
            "Generating forecasts for Validation (43-82)...\n",
            "\n",
            "Generating forecasts for Validation (43-83)...\n",
            "\n",
            "Generating forecasts for Validation (43-85)...\n",
            "\n",
            "Generating forecasts for Validation (43-87)...\n",
            "\n",
            "Generating forecasts for Validation (43-90)...\n",
            "\n",
            "Generating forecasts for Validation (43-91)...\n",
            "\n",
            "Generating forecasts for Validation (43-92)...\n",
            "\n",
            "Generating forecasts for Validation (43-93)...\n",
            "\n",
            "Generating forecasts for Validation (43-94)...\n",
            "\n",
            "Generating forecasts for Validation (43-95)...\n",
            "\n",
            "Generating forecasts for Validation (43-96)...\n",
            "\n",
            "Generating forecasts for Validation (43-97)...\n",
            "\n",
            "Generating forecasts for Validation (43-98)...\n",
            "\n",
            "Generating forecasts for Validation (43-99)...\n",
            "\n",
            "Generating forecasts for Validation (44-1)...\n",
            "\n",
            "Generating forecasts for Validation (44-2)...\n",
            "\n",
            "Generating forecasts for Validation (44-3)...\n",
            "\n",
            "Generating forecasts for Validation (44-4)...\n",
            "\n",
            "Generating forecasts for Validation (44-5)...\n",
            "\n",
            "Generating forecasts for Validation (44-6)...\n",
            "\n",
            "Generating forecasts for Validation (44-7)...\n",
            "\n",
            "Generating forecasts for Validation (44-8)...\n",
            "\n",
            "Generating forecasts for Validation (44-9)...\n",
            "\n",
            "Generating forecasts for Validation (44-10)...\n",
            "\n",
            "Generating forecasts for Validation (44-11)...\n",
            "\n",
            "Generating forecasts for Validation (44-12)...\n",
            "\n",
            "Generating forecasts for Validation (44-13)...\n",
            "\n",
            "Generating forecasts for Validation (44-14)...\n",
            "\n",
            "Generating forecasts for Validation (44-16)...\n",
            "\n",
            "Generating forecasts for Validation (44-17)...\n",
            "\n",
            "Generating forecasts for Validation (44-18)...\n",
            "\n",
            "Generating forecasts for Validation (44-20)...\n",
            "\n",
            "Generating forecasts for Validation (44-21)...\n",
            "\n",
            "Generating forecasts for Validation (44-22)...\n",
            "\n",
            "Generating forecasts for Validation (44-23)...\n",
            "\n",
            "Generating forecasts for Validation (44-24)...\n",
            "\n",
            "Generating forecasts for Validation (44-25)...\n",
            "\n",
            "Generating forecasts for Validation (44-26)...\n",
            "\n",
            "Generating forecasts for Validation (44-27)...\n",
            "\n",
            "Generating forecasts for Validation (44-28)...\n",
            "\n",
            "Generating forecasts for Validation (44-31)...\n",
            "\n",
            "Generating forecasts for Validation (44-32)...\n",
            "\n",
            "Generating forecasts for Validation (44-33)...\n",
            "\n",
            "Generating forecasts for Validation (44-38)...\n",
            "\n",
            "Generating forecasts for Validation (44-40)...\n",
            "\n",
            "Generating forecasts for Validation (44-42)...\n",
            "\n",
            "Generating forecasts for Validation (44-44)...\n",
            "\n",
            "Generating forecasts for Validation (44-46)...\n",
            "\n",
            "Generating forecasts for Validation (44-49)...\n",
            "\n",
            "Generating forecasts for Validation (44-52)...\n",
            "\n",
            "Generating forecasts for Validation (44-55)...\n",
            "\n",
            "Generating forecasts for Validation (44-56)...\n",
            "\n",
            "Generating forecasts for Validation (44-59)...\n",
            "\n",
            "Generating forecasts for Validation (44-60)...\n",
            "\n",
            "Generating forecasts for Validation (44-67)...\n",
            "\n",
            "Generating forecasts for Validation (44-71)...\n",
            "\n",
            "Generating forecasts for Validation (44-72)...\n",
            "\n",
            "Generating forecasts for Validation (44-74)...\n",
            "\n",
            "Generating forecasts for Validation (44-79)...\n",
            "\n",
            "Generating forecasts for Validation (44-80)...\n",
            "\n",
            "Generating forecasts for Validation (44-81)...\n",
            "\n",
            "Generating forecasts for Validation (44-82)...\n",
            "\n",
            "Generating forecasts for Validation (44-83)...\n",
            "\n",
            "Generating forecasts for Validation (44-85)...\n",
            "\n",
            "Generating forecasts for Validation (44-87)...\n",
            "\n",
            "Generating forecasts for Validation (44-90)...\n",
            "\n",
            "Generating forecasts for Validation (44-91)...\n",
            "\n",
            "Generating forecasts for Validation (44-92)...\n",
            "\n",
            "Generating forecasts for Validation (44-93)...\n",
            "\n",
            "Generating forecasts for Validation (44-94)...\n",
            "\n",
            "Generating forecasts for Validation (44-95)...\n",
            "\n",
            "Generating forecasts for Validation (44-96)...\n",
            "\n",
            "Generating forecasts for Validation (44-97)...\n",
            "\n",
            "Generating forecasts for Validation (44-98)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/statsmodels/base/model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Generating forecasts for Validation (44-99)...\n",
            "\n",
            "Generating forecasts for Validation (45-1)...\n",
            "\n",
            "Generating forecasts for Validation (45-2)...\n",
            "\n",
            "Generating forecasts for Validation (45-3)...\n",
            "\n",
            "Generating forecasts for Validation (45-4)...\n",
            "\n",
            "Generating forecasts for Validation (45-5)...\n",
            "\n",
            "Generating forecasts for Validation (45-6)...\n",
            "\n",
            "Generating forecasts for Validation (45-7)...\n",
            "\n",
            "Generating forecasts for Validation (45-8)...\n",
            "\n",
            "Generating forecasts for Validation (45-9)...\n",
            "\n",
            "Generating forecasts for Validation (45-10)...\n",
            "\n",
            "Generating forecasts for Validation (45-11)...\n",
            "\n",
            "Generating forecasts for Validation (45-12)...\n",
            "\n",
            "Generating forecasts for Validation (45-13)...\n",
            "\n",
            "Generating forecasts for Validation (45-14)...\n",
            "\n",
            "Generating forecasts for Validation (45-16)...\n",
            "\n",
            "Generating forecasts for Validation (45-17)...\n",
            "\n",
            "Generating forecasts for Validation (45-18)...\n",
            "\n",
            "Generating forecasts for Validation (45-19)...\n",
            "\n",
            "Generating forecasts for Validation (45-20)...\n",
            "\n",
            "Generating forecasts for Validation (45-21)...\n",
            "\n",
            "Generating forecasts for Validation (45-22)...\n",
            "\n",
            "Generating forecasts for Validation (45-23)...\n",
            "\n",
            "Generating forecasts for Validation (45-24)...\n",
            "\n",
            "Generating forecasts for Validation (45-25)...\n",
            "\n",
            "Generating forecasts for Validation (45-26)...\n",
            "\n",
            "Generating forecasts for Validation (45-27)...\n",
            "\n",
            "Generating forecasts for Validation (45-28)...\n",
            "\n",
            "Generating forecasts for Validation (45-29)...\n",
            "\n",
            "Generating forecasts for Validation (45-30)...\n",
            "\n",
            "Generating forecasts for Validation (45-31)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/statsmodels/base/model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Generating forecasts for Validation (45-32)...\n",
            "\n",
            "Generating forecasts for Validation (45-33)...\n",
            "\n",
            "Generating forecasts for Validation (45-34)...\n",
            "\n",
            "Generating forecasts for Validation (45-35)...\n",
            "\n",
            "Generating forecasts for Validation (45-36)...\n",
            "\n",
            "Generating forecasts for Validation (45-38)...\n",
            "\n",
            "Generating forecasts for Validation (45-40)...\n",
            "\n",
            "Generating forecasts for Validation (45-41)...\n",
            "\n",
            "Generating forecasts for Validation (45-42)...\n",
            "\n",
            "Generating forecasts for Validation (45-44)...\n",
            "\n",
            "Generating forecasts for Validation (45-45)...\n",
            "\n",
            "Generating forecasts for Validation (45-46)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/statsmodels/base/model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Generating forecasts for Validation (45-47)...\n",
            "\n",
            "Generating forecasts for Validation (45-49)...\n",
            "\n",
            "Generating forecasts for Validation (45-51)...\n",
            "\n",
            "Generating forecasts for Validation (45-52)...\n",
            "\n",
            "Generating forecasts for Validation (45-54)...\n",
            "\n",
            "Generating forecasts for Validation (45-55)...\n",
            "\n",
            "Generating forecasts for Validation (45-56)...\n",
            "\n",
            "Generating forecasts for Validation (45-58)...\n",
            "\n",
            "Generating forecasts for Validation (45-59)...\n",
            "\n",
            "Generating forecasts for Validation (45-60)...\n",
            "\n",
            "Generating forecasts for Validation (45-67)...\n",
            "\n",
            "Generating forecasts for Validation (45-71)...\n",
            "\n",
            "Generating forecasts for Validation (45-72)...\n",
            "\n",
            "Generating forecasts for Validation (45-74)...\n",
            "\n",
            "Generating forecasts for Validation (45-77)...\n",
            "\n",
            "Generating forecasts for Validation (45-78)...\n",
            "\n",
            "Generating forecasts for Validation (45-79)...\n",
            "\n",
            "Generating forecasts for Validation (45-80)...\n",
            "\n",
            "Generating forecasts for Validation (45-81)...\n",
            "\n",
            "Generating forecasts for Validation (45-82)...\n",
            "\n",
            "Generating forecasts for Validation (45-83)...\n",
            "\n",
            "Generating forecasts for Validation (45-85)...\n",
            "\n",
            "Generating forecasts for Validation (45-87)...\n",
            "\n",
            "Generating forecasts for Validation (45-90)...\n",
            "\n",
            "Generating forecasts for Validation (45-91)...\n",
            "\n",
            "Generating forecasts for Validation (45-92)...\n",
            "\n",
            "Generating forecasts for Validation (45-93)...\n",
            "\n",
            "Generating forecasts for Validation (45-94)...\n",
            "\n",
            "Generating forecasts for Validation (45-95)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/statsmodels/base/model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Generating forecasts for Validation (45-96)...\n",
            "\n",
            "Generating forecasts for Validation (45-97)...\n",
            "\n",
            "Generating forecasts for Validation (45-98)...\n",
            "✅ Local Validation WMAE: 2127.29\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from statsmodels.tsa.arima.model import ARIMA\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "def simple_arima_forecasting():\n",
        "    \"\"\"\n",
        "    Simple, robust ARIMA-based Walmart forecasting approach\n",
        "    \"\"\"\n",
        "    print(\"=\" * 60)\n",
        "    print(\"SIMPLE ARIMA FORECASTING - ROBUST APPROACH\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    print(\"Loading data...\")\n",
        "    train = pd.read_csv('walmart_data/train.csv')\n",
        "    test = pd.read_csv('walmart_data/test.csv')\n",
        "    stores = pd.read_csv('walmart_data/stores.csv')\n",
        "    features = pd.read_csv('walmart_data/features.csv')\n",
        "\n",
        "    train['Date'] = pd.to_datetime(train['Date'])\n",
        "    test['Date'] = pd.to_datetime(test['Date'])\n",
        "    features['Date'] = pd.to_datetime(features['Date'])\n",
        "\n",
        "    train_merged = train.merge(stores, on='Store', how='left')\n",
        "    train_merged = train_merged.merge(features, on=['Store', 'Date'], how='left')\n",
        "    test_merged = test.merge(stores, on='Store', how='left')\n",
        "    test_merged = test_merged.merge(features, on=['Store', 'Date'], how='left')\n",
        "\n",
        "    if 'IsHoliday_x' in train_merged.columns and 'IsHoliday_y' in train_merged.columns:\n",
        "        train_merged['IsHoliday'] = train_merged['IsHoliday_x'] | train_merged['IsHoliday_y']\n",
        "        test_merged['IsHoliday'] = test_merged['IsHoliday_x'] | test_merged['IsHoliday_y']\n",
        "        train_merged = train_merged.drop(['IsHoliday_x', 'IsHoliday_y'], axis=1)\n",
        "        test_merged = test_merged.drop(['IsHoliday_x', 'IsHoliday_y'], axis=1)\n",
        "\n",
        "    train_merged = train_merged.fillna(0)\n",
        "    test_merged = test_merged.fillna(0)\n",
        "\n",
        "    print(\"Creating validation split...\")\n",
        "    train_merged = train_merged.sort_values('Date')\n",
        "    split_date = train_merged['Date'].max() - pd.DateOffset(weeks=13)\n",
        "\n",
        "    train_val = train_merged[train_merged['Date'] <= split_date]\n",
        "    val_data = train_merged[train_merged['Date'] > split_date]\n",
        "\n",
        "    print(f\"Training period: {train_val['Date'].min()} to {train_val['Date'].max()}\")\n",
        "    print(f\"Validation period: {val_data['Date'].min()} to {val_data['Date'].max()}\")\n",
        "\n",
        "    holiday_multiplier = train_val[train_val['IsHoliday']]['Weekly_Sales'].mean() / train_val[~train_val['IsHoliday']]['Weekly_Sales'].mean()\n",
        "    print(f\"Holiday multiplier: {holiday_multiplier:.3f}\")\n",
        "\n",
        "    print(\"Creating simple forecasts with ARIMA adjustments...\")\n",
        "\n",
        "    val_predictions = []\n",
        "    val_actuals = []\n",
        "    val_holidays = []\n",
        "\n",
        "    val_combinations = val_data.groupby(['Store', 'Dept']).size().reset_index()\n",
        "\n",
        "    for _, row in val_combinations.iterrows():\n",
        "        store = row['Store']\n",
        "        dept = row['Dept']\n",
        "\n",
        "        train_store_dept = train_val[(train_val['Store'] == store) & (train_val['Dept'] == dept)]\n",
        "        val_store_dept = val_data[(val_data['Store'] == store) & (val_data['Dept'] == dept)]\n",
        "\n",
        "        if len(train_store_dept) >= 10:\n",
        "            train_store_dept = train_store_dept.sort_values('Date')\n",
        "            train_store_dept.set_index('Date', inplace=True)\n",
        "\n",
        "            ts = train_store_dept['Weekly_Sales'].resample('W').sum()\n",
        "            ts = ts.fillna(method='ffill').fillna(0)\n",
        "\n",
        "            if len(ts) >= 10:\n",
        "                try:\n",
        "                    model = ARIMA(ts, order=(1, 1, 1))\n",
        "                    fitted_model = model.fit()\n",
        "                    n_forecast = len(val_store_dept)\n",
        "                    if n_forecast > 0:\n",
        "                        forecast = fitted_model.forecast(steps=n_forecast)\n",
        "\n",
        "                        for i, (idx, val_row) in enumerate(val_store_dept.iterrows()):\n",
        "                            if i < len(forecast):\n",
        "                                base_forecast = forecast[i]\n",
        "                            else:\n",
        "                                base_forecast = ts.mean()\n",
        "\n",
        "                            if val_row['IsHoliday']:\n",
        "                                forecast_value = base_forecast * holiday_multiplier\n",
        "                            else:\n",
        "                                forecast_value = base_forecast\n",
        "\n",
        "                            forecast_value = max(0, forecast_value)\n",
        "                            val_predictions.append(forecast_value)\n",
        "                            val_actuals.append(val_row['Weekly_Sales'])\n",
        "                            val_holidays.append(val_row['IsHoliday'])\n",
        "                        continue\n",
        "\n",
        "                except Exception as e:\n",
        "                    print(f\"ARIMA failed for store {store}, dept {dept}: {e}\")\n",
        "\n",
        "        if len(train_store_dept) > 0:\n",
        "            base_forecast = train_store_dept['Weekly_Sales'].mean()\n",
        "        else:\n",
        "            base_forecast = train_val['Weekly_Sales'].mean()\n",
        "\n",
        "        for idx, val_row in val_store_dept.iterrows():\n",
        "            if val_row['IsHoliday']:\n",
        "                forecast_value = base_forecast * holiday_multiplier\n",
        "            else:\n",
        "                forecast_value = base_forecast\n",
        "\n",
        "            forecast_value = max(0, forecast_value)\n",
        "            val_predictions.append(forecast_value)\n",
        "            val_actuals.append(val_row['Weekly_Sales'])\n",
        "            val_holidays.append(val_row['IsHoliday'])\n",
        "\n",
        "    def compute_wmae(y_true, y_pred, is_holiday):\n",
        "        weights = np.where(is_holiday, 5, 1)\n",
        "        wmae = np.sum(weights * np.abs(y_true - y_pred)) / np.sum(weights)\n",
        "        return wmae\n",
        "\n",
        "    wmae = compute_wmae(np.array(val_actuals), np.array(val_predictions), np.array(val_holidays))\n",
        "    print(f\"✅ Simple ARIMA Local Validation WMAE: {wmae:.2f}\")\n",
        "\n",
        "    print(f\"\\nValidation Statistics:\")\n",
        "    print(f\"  Total validation rows: {len(val_actuals)}\")\n",
        "    print(f\"  Holiday rows: {sum(val_holidays)}\")\n",
        "    print(f\"  Non-holiday rows: {len(val_holidays) - sum(val_holidays)}\")\n",
        "    print(f\"  Average actual sales: {np.mean(val_actuals):.2f}\")\n",
        "    print(f\"  Average predicted sales: {np.mean(val_predictions):.2f}\")\n",
        "\n",
        "    return wmae\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    wmae = simple_arima_forecasting()\n",
        "    print(f\"\\n🎉 Final WMAE Score: {wmae:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jz_Vx-bq9C-L",
        "outputId": "49674465-33c3-48e4-e500-e00f54876d0b"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "SIMPLE ARIMA FORECASTING - ROBUST APPROACH\n",
            "============================================================\n",
            "Loading data...\n",
            "Creating validation split...\n",
            "Training period: 2010-02-05 00:00:00 to 2012-07-27 00:00:00\n",
            "Validation period: 2012-08-03 00:00:00 to 2012-10-26 00:00:00\n",
            "Holiday multiplier: 1.074\n",
            "Creating simple forecasts with ARIMA adjustments...\n",
            "✅ Simple ARIMA Local Validation WMAE: 2213.76\n",
            "\n",
            "Validation Statistics:\n",
            "  Total validation rows: 38530\n",
            "  Holiday rows: 2966\n",
            "  Non-holiday rows: 35564\n",
            "  Average actual sales: 15620.50\n",
            "  Average predicted sales: 15948.62\n",
            "\n",
            "🎉 Final WMAE Score: 2213.76\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from statsmodels.tsa.arima.model import ARIMA\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "def optimized_arima_forecasting():\n",
        "    \"\"\"\n",
        "    Optimized ARIMA-based Walmart forecasting approach to get WMAE below 2000\n",
        "    \"\"\"\n",
        "    print(\"=\" * 60)\n",
        "    print(\"OPTIMIZED ARIMA FORECASTING - TARGET WMAE < 2000\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    print(\"Loading data...\")\n",
        "    train = pd.read_csv('walmart_data/train.csv')\n",
        "    test = pd.read_csv('walmart_data/test.csv')\n",
        "    stores = pd.read_csv('walmart_data/stores.csv')\n",
        "    features = pd.read_csv('walmart_data/features.csv')\n",
        "\n",
        "    train['Date'] = pd.to_datetime(train['Date'])\n",
        "    test['Date'] = pd.to_datetime(test['Date'])\n",
        "    features['Date'] = pd.to_datetime(features['Date'])\n",
        "\n",
        "    train_merged = train.merge(stores, on='Store', how='left')\n",
        "    train_merged = train_merged.merge(features, on=['Store', 'Date'], how='left')\n",
        "    test_merged = test.merge(stores, on='Store', how='left')\n",
        "    test_merged = test_merged.merge(features, on=['Store', 'Date'], how='left')\n",
        "\n",
        "    if 'IsHoliday_x' in train_merged.columns and 'IsHoliday_y' in train_merged.columns:\n",
        "        train_merged['IsHoliday'] = train_merged['IsHoliday_x'] | train_merged['IsHoliday_y']\n",
        "        test_merged['IsHoliday'] = test_merged['IsHoliday_x'] | test_merged['IsHoliday_y']\n",
        "        train_merged = train_merged.drop(['IsHoliday_x', 'IsHoliday_y'], axis=1)\n",
        "        test_merged = test_merged.drop(['IsHoliday_x', 'IsHoliday_y'], axis=1)\n",
        "\n",
        "    train_merged = train_merged.fillna(0)\n",
        "    test_merged = test_merged.fillna(0)\n",
        "\n",
        "    print(\"Creating enhanced features...\")\n",
        "\n",
        "    train_merged['Month'] = train_merged['Date'].dt.month\n",
        "    train_merged['Week'] = train_merged['Date'].dt.isocalendar().week\n",
        "    train_merged['DayOfYear'] = train_merged['Date'].dt.dayofyear\n",
        "\n",
        "    store_dept_stats = train_merged.groupby(['Store', 'Dept']).agg({\n",
        "        'Weekly_Sales': ['mean', 'std', 'median', 'min', 'max'],\n",
        "        'Temperature': 'mean',\n",
        "        'Fuel_Price': 'mean',\n",
        "        'CPI': 'mean',\n",
        "        'Unemployment': 'mean'\n",
        "    }).reset_index()\n",
        "\n",
        "    store_dept_stats.columns = ['Store', 'Dept', 'Sales_Mean', 'Sales_Std', 'Sales_Median',\n",
        "                               'Sales_Min', 'Sales_Max', 'Temp_Mean', 'Fuel_Mean', 'CPI_Mean', 'Unemp_Mean']\n",
        "\n",
        "    train_merged = train_merged.merge(store_dept_stats, on=['Store', 'Dept'], how='left')\n",
        "    test_merged = test_merged.merge(store_dept_stats, on=['Store', 'Dept'], how='left')\n",
        "\n",
        "    print(\"Creating validation split...\")\n",
        "    train_merged = train_merged.sort_values('Date')\n",
        "    split_date = train_merged['Date'].max() - pd.DateOffset(weeks=13)\n",
        "\n",
        "    train_val = train_merged[train_merged['Date'] <= split_date]\n",
        "    val_data = train_merged[train_merged['Date'] > split_date]\n",
        "\n",
        "    print(f\"Training period: {train_val['Date'].min()} to {train_val['Date'].max()}\")\n",
        "    print(f\"Validation period: {val_data['Date'].min()} to {val_data['Date'].max()}\")\n",
        "\n",
        "    print(\"Calculating store-dept specific holiday multipliers...\")\n",
        "    holiday_multipliers = {}\n",
        "\n",
        "    for store in train_val['Store'].unique():\n",
        "        for dept in train_val[train_val['Store'] == store]['Dept'].unique():\n",
        "            store_dept_data = train_val[(train_val['Store'] == store) & (train_val['Dept'] == dept)]\n",
        "            if len(store_dept_data) > 0:\n",
        "                holiday_data = store_dept_data[store_dept_data['IsHoliday']]\n",
        "                non_holiday_data = store_dept_data[~store_dept_data['IsHoliday']]\n",
        "\n",
        "                if len(holiday_data) > 0 and len(non_holiday_data) > 0:\n",
        "                    holiday_avg = holiday_data['Weekly_Sales'].mean()\n",
        "                    non_holiday_avg = non_holiday_data['Weekly_Sales'].mean()\n",
        "                    if non_holiday_avg > 0:\n",
        "                        holiday_multipliers[(store, dept)] = holiday_avg / non_holiday_avg\n",
        "                    else:\n",
        "                        holiday_multipliers[(store, dept)] = 1.2\n",
        "                else:\n",
        "                    holiday_multipliers[(store, dept)] = 1.2\n",
        "            else:\n",
        "                holiday_multipliers[(store, dept)] = 1.2\n",
        "\n",
        "    global_holiday_multiplier = train_val[train_val['IsHoliday']]['Weekly_Sales'].mean() / train_val[~train_val['IsHoliday']]['Weekly_Sales'].mean()\n",
        "    print(f\"Global holiday multiplier: {global_holiday_multiplier:.3f}\")\n",
        "\n",
        "    print(\"Creating optimized forecasts...\")\n",
        "\n",
        "    val_predictions = []\n",
        "    val_actuals = []\n",
        "    val_holidays = []\n",
        "\n",
        "    val_combinations = val_data.groupby(['Store', 'Dept']).size().reset_index()\n",
        "\n",
        "    for _, row in val_combinations.iterrows():\n",
        "        store = row['Store']\n",
        "        dept = row['Dept']\n",
        "\n",
        "        train_store_dept = train_val[(train_val['Store'] == store) & (train_val['Dept'] == dept)]\n",
        "        val_store_dept = val_data[(val_data['Store'] == store) & (val_data['Dept'] == dept)]\n",
        "\n",
        "        if len(train_store_dept) >= 15:\n",
        "            train_store_dept = train_store_dept.sort_values('Date')\n",
        "            train_store_dept.set_index('Date', inplace=True)\n",
        "\n",
        "            ts = train_store_dept['Weekly_Sales'].resample('W').sum()\n",
        "            ts = ts.fillna(method='ffill').fillna(0)\n",
        "\n",
        "            if len(ts) >= 15:\n",
        "                try:\n",
        "                    configs = [(1, 1, 1), (2, 1, 1), (1, 1, 2), (0, 1, 1), (1, 0, 1), (2, 1, 2)]\n",
        "                    best_aic = float('inf')\n",
        "                    best_model = None\n",
        "\n",
        "                    for order in configs:\n",
        "                        try:\n",
        "                            model = ARIMA(ts, order=order)\n",
        "                            fitted = model.fit()\n",
        "                            if fitted.aic < best_aic:\n",
        "                                best_aic = fitted.aic\n",
        "                                best_model = fitted\n",
        "                        except:\n",
        "                            continue\n",
        "\n",
        "                    if best_model is not None:\n",
        "                        n_forecast = len(val_store_dept)\n",
        "                        if n_forecast > 0:\n",
        "                            forecast = best_model.forecast(steps=n_forecast)\n",
        "\n",
        "                            for i, (idx, val_row) in enumerate(val_store_dept.iterrows()):\n",
        "                                if i < len(forecast):\n",
        "                                    base_forecast = forecast[i]\n",
        "                                else:\n",
        "                                    base_forecast = ts.mean()\n",
        "\n",
        "                                holiday_mult = holiday_multipliers.get((store, dept), global_holiday_multiplier)\n",
        "\n",
        "                                if val_row['IsHoliday']:\n",
        "                                    forecast_value = base_forecast * holiday_mult\n",
        "                                else:\n",
        "                                    forecast_value = base_forecast\n",
        "\n",
        "                                if val_row['Temperature'] > 80:\n",
        "                                    forecast_value *= 0.95\n",
        "                                elif val_row['Temperature'] < 30:\n",
        "                                    forecast_value *= 1.05\n",
        "\n",
        "                                forecast_value = max(0, forecast_value)\n",
        "                                val_predictions.append(forecast_value)\n",
        "                                val_actuals.append(val_row['Weekly_Sales'])\n",
        "                                val_holidays.append(val_row['IsHoliday'])\n",
        "                            continue\n",
        "\n",
        "                except Exception as e:\n",
        "                    print(f\"ARIMA failed for store {store}, dept {dept}: {e}\")\n",
        "\n",
        "        if len(train_store_dept) > 0:\n",
        "            train_store_dept['Month'] = train_store_dept['Date'].dt.month\n",
        "            monthly_avg = train_store_dept.groupby('Month')['Weekly_Sales'].mean()\n",
        "\n",
        "            recent_data = train_store_dept.tail(20)\n",
        "            recent_avg = recent_data['Weekly_Sales'].mean()\n",
        "\n",
        "            base_forecast = 0.7 * recent_avg + 0.3 * train_store_dept['Weekly_Sales'].mean()\n",
        "        else:\n",
        "            base_forecast = train_val['Weekly_Sales'].mean()\n",
        "\n",
        "        for idx, val_row in val_store_dept.iterrows():\n",
        "            holiday_mult = holiday_multipliers.get((store, dept), global_holiday_multiplier)\n",
        "\n",
        "            if val_row['IsHoliday']:\n",
        "                forecast_value = base_forecast * holiday_mult\n",
        "            else:\n",
        "                forecast_value = base_forecast\n",
        "\n",
        "            if val_row['Temperature'] > 80:\n",
        "                forecast_value *= 0.95\n",
        "            elif val_row['Temperature'] < 30:\n",
        "                forecast_value *= 1.05\n",
        "\n",
        "            forecast_value = max(0, forecast_value)\n",
        "            val_predictions.append(forecast_value)\n",
        "            val_actuals.append(val_row['Weekly_Sales'])\n",
        "            val_holidays.append(val_row['IsHoliday'])\n",
        "\n",
        "    def compute_wmae(y_true, y_pred, is_holiday):\n",
        "        weights = np.where(is_holiday, 5, 1)\n",
        "        wmae = np.sum(weights * np.abs(y_true - y_pred)) / np.sum(weights)\n",
        "        return wmae\n",
        "\n",
        "    wmae = compute_wmae(np.array(val_actuals), np.array(val_predictions), np.array(val_holidays))\n",
        "    print(f\"✅ Optimized ARIMA Local Validation WMAE: {wmae:.2f}\")\n",
        "\n",
        "    print(f\"\\nValidation Statistics:\")\n",
        "    print(f\"  Total validation rows: {len(val_actuals)}\")\n",
        "    print(f\"  Holiday rows: {sum(val_holidays)}\")\n",
        "    print(f\"  Non-holiday rows: {len(val_holidays) - sum(val_holidays)}\")\n",
        "    print(f\"  Average actual sales: {np.mean(val_actuals):.2f}\")\n",
        "    print(f\"  Average predicted sales: {np.mean(val_predictions):.2f}\")\n",
        "    print(f\"  MAE (non-weighted): {np.mean(np.abs(np.array(val_actuals) - np.array(val_predictions))):.2f}\")\n",
        "\n",
        "    return wmae\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    wmae = optimized_arima_forecasting()\n",
        "    print(f\"\\n🎉 Final WMAE Score: {wmae:.2f}\")\n",
        "    if wmae < 2000:\n",
        "        print(\"🎯 SUCCESS! WMAE is below 2000!\")\n",
        "    else:\n",
        "        print(\"📈 Close! Try running again or further optimizations needed.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nPN2l1HrH4cU",
        "outputId": "3f82299e-54ee-427f-eae3-754ce58fc9f5"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "OPTIMIZED ARIMA FORECASTING - TARGET WMAE < 2000\n",
            "============================================================\n",
            "Loading data...\n",
            "Creating enhanced features...\n",
            "Creating validation split...\n",
            "Training period: 2010-02-05 00:00:00 to 2012-07-27 00:00:00\n",
            "Validation period: 2012-08-03 00:00:00 to 2012-10-26 00:00:00\n",
            "Calculating store-dept specific holiday multipliers...\n",
            "Global holiday multiplier: 1.074\n",
            "Creating optimized forecasts...\n",
            "✅ Optimized ARIMA Local Validation WMAE: 2550.43\n",
            "\n",
            "Validation Statistics:\n",
            "  Total validation rows: 38530\n",
            "  Holiday rows: 2966\n",
            "  Non-holiday rows: 35564\n",
            "  Average actual sales: 15620.50\n",
            "  Average predicted sales: 15819.96\n",
            "  MAE (non-weighted): 2186.85\n",
            "\n",
            "🎉 Final WMAE Score: 2550.43\n",
            "📈 Close! Try running again or further optimizations needed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from statsmodels.tsa.arima.model import ARIMA\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "def fast_optimized_arima_forecasting():\n",
        "    \"\"\"\n",
        "    Fast optimized ARIMA-based Walmart forecasting approach\n",
        "    \"\"\"\n",
        "    print(\"=\" * 60)\n",
        "    print(\"FAST OPTIMIZED ARIMA FORECASTING\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    print(\"Loading data...\")\n",
        "    train = pd.read_csv('walmart_data/train.csv')\n",
        "    test = pd.read_csv('walmart_data/test.csv')\n",
        "    stores = pd.read_csv('walmart_data/stores.csv')\n",
        "    features = pd.read_csv('walmart_data/features.csv')\n",
        "\n",
        "    train['Date'] = pd.to_datetime(train['Date'])\n",
        "    test['Date'] = pd.to_datetime(test['Date'])\n",
        "    features['Date'] = pd.to_datetime(features['Date'])\n",
        "\n",
        "    train_merged = train.merge(stores, on='Store', how='left')\n",
        "    train_merged = train_merged.merge(features, on=['Store', 'Date'], how='left')\n",
        "    test_merged = test.merge(stores, on='Store', how='left')\n",
        "    test_merged = test_merged.merge(features, on=['Store', 'Date'], how='left')\n",
        "\n",
        "    if 'IsHoliday_x' in train_merged.columns and 'IsHoliday_y' in train_merged.columns:\n",
        "        train_merged['IsHoliday'] = train_merged['IsHoliday_x'] | train_merged['IsHoliday_y']\n",
        "        test_merged['IsHoliday'] = test_merged['IsHoliday_x'] | test_merged['IsHoliday_y']\n",
        "        train_merged = train_merged.drop(['IsHoliday_x', 'IsHoliday_y'], axis=1)\n",
        "        test_merged = test_merged.drop(['IsHoliday_x', 'IsHoliday_y'], axis=1)\n",
        "\n",
        "    train_merged = train_merged.fillna(0)\n",
        "    test_merged = test_merged.fillna(0)\n",
        "\n",
        "    print(\"Creating validation split...\")\n",
        "    train_merged = train_merged.sort_values('Date')\n",
        "    split_date = train_merged['Date'].max() - pd.DateOffset(weeks=13)\n",
        "\n",
        "    train_val = train_merged[train_merged['Date'] <= split_date]\n",
        "    val_data = train_merged[train_merged['Date'] > split_date]\n",
        "\n",
        "    print(f\"Training period: {train_val['Date'].min()} to {train_val['Date'].max()}\")\n",
        "    print(f\"Validation period: {val_data['Date'].min()} to {val_data['Date'].max()}\")\n",
        "\n",
        "    holiday_multiplier = train_val[train_val['IsHoliday']]['Weekly_Sales'].mean() / train_val[~train_val['IsHoliday']]['Weekly_Sales'].mean()\n",
        "    print(f\"Holiday multiplier: {holiday_multiplier:.3f}\")\n",
        "\n",
        "    print(\"Creating fast optimized forecasts...\")\n",
        "\n",
        "    val_predictions = []\n",
        "    val_actuals = []\n",
        "    val_holidays = []\n",
        "\n",
        "    val_combinations = val_data.groupby(['Store', 'Dept']).size().reset_index()\n",
        "    print(f\"Processing {len(val_combinations)} store-dept combinations...\")\n",
        "\n",
        "    for idx, row in val_combinations.iterrows():\n",
        "        if idx % 10 == 0:\n",
        "            print(f\"Processing combination {idx+1}/{len(val_combinations)}\")\n",
        "\n",
        "        store = row['Store']\n",
        "        dept = row['Dept']\n",
        "\n",
        "        train_store_dept = train_val[(train_val['Store'] == store) & (train_val['Dept'] == dept)]\n",
        "        val_store_dept = val_data[(val_data['Store'] == store) & (val_data['Dept'] == dept)]\n",
        "\n",
        "        if len(train_store_dept) >= 12:\n",
        "            train_store_dept = train_store_dept.sort_values('Date')\n",
        "            train_store_dept.set_index('Date', inplace=True)\n",
        "\n",
        "            ts = train_store_dept['Weekly_Sales'].resample('W').sum()\n",
        "            ts = ts.fillna(method='ffill').fillna(0)\n",
        "\n",
        "            if len(ts) >= 12:\n",
        "                try:\n",
        "                    configs = [(1, 1, 1), (2, 1, 1), (1, 1, 2)]\n",
        "                    best_aic = float('inf')\n",
        "                    best_model = None\n",
        "\n",
        "                    for order in configs:\n",
        "                        try:\n",
        "                            model = ARIMA(ts, order=order)\n",
        "                            fitted = model.fit()\n",
        "                            if fitted.aic < best_aic:\n",
        "                                best_aic = fitted.aic\n",
        "                                best_model = fitted\n",
        "                        except:\n",
        "                            continue\n",
        "\n",
        "                    if best_model is not None:\n",
        "                        n_forecast = len(val_store_dept)\n",
        "                        if n_forecast > 0:\n",
        "                            forecast = best_model.forecast(steps=n_forecast)\n",
        "\n",
        "                            for i, (idx, val_row) in enumerate(val_store_dept.iterrows()):\n",
        "                                if i < len(forecast):\n",
        "                                    base_forecast = forecast[i]\n",
        "                                else:\n",
        "                                    base_forecast = ts.mean()\n",
        "\n",
        "                                if val_row['IsHoliday']:\n",
        "                                    forecast_value = base_forecast * holiday_multiplier\n",
        "                                else:\n",
        "                                    forecast_value = base_forecast\n",
        "\n",
        "                                if val_row['Temperature'] > 80:\n",
        "                                    forecast_value *= 0.98\n",
        "                                elif val_row['Temperature'] < 30:\n",
        "                                    forecast_value *= 1.02\n",
        "\n",
        "                                forecast_value = max(0, forecast_value)\n",
        "                                val_predictions.append(forecast_value)\n",
        "                                val_actuals.append(val_row['Weekly_Sales'])\n",
        "                                val_holidays.append(val_row['IsHoliday'])\n",
        "                            continue\n",
        "\n",
        "                except Exception as e:\n",
        "                    pass\n",
        "\n",
        "        if len(train_store_dept) > 0:\n",
        "            recent_data = train_store_dept.tail(15)\n",
        "            recent_avg = recent_data['Weekly_Sales'].mean()\n",
        "            overall_avg = train_store_dept['Weekly_Sales'].mean()\n",
        "\n",
        "            base_forecast = 0.8 * recent_avg + 0.2 * overall_avg\n",
        "        else:\n",
        "            base_forecast = train_val['Weekly_Sales'].mean()\n",
        "\n",
        "        for idx, val_row in val_store_dept.iterrows():\n",
        "            if val_row['IsHoliday']:\n",
        "                forecast_value = base_forecast * holiday_multiplier\n",
        "            else:\n",
        "                forecast_value = base_forecast\n",
        "\n",
        "            if val_row['Temperature'] > 80:\n",
        "                forecast_value *= 0.98\n",
        "            elif val_row['Temperature'] < 30:\n",
        "                forecast_value *= 1.02\n",
        "\n",
        "            forecast_value = max(0, forecast_value)\n",
        "            val_predictions.append(forecast_value)\n",
        "            val_actuals.append(val_row['Weekly_Sales'])\n",
        "            val_holidays.append(val_row['IsHoliday'])\n",
        "\n",
        "    def compute_wmae(y_true, y_pred, is_holiday):\n",
        "        weights = np.where(is_holiday, 5, 1)\n",
        "        wmae = np.sum(weights * np.abs(y_true - y_pred)) / np.sum(weights)\n",
        "        return wmae\n",
        "\n",
        "    wmae = compute_wmae(np.array(val_actuals), np.array(val_predictions), np.array(val_holidays))\n",
        "    print(f\"✅ Fast Optimized ARIMA Local Validation WMAE: {wmae:.2f}\")\n",
        "\n",
        "    print(f\"\\nValidation Statistics:\")\n",
        "    print(f\"  Total validation rows: {len(val_actuals)}\")\n",
        "    print(f\"  Holiday rows: {sum(val_holidays)}\")\n",
        "    print(f\"  Non-holiday rows: {len(val_holidays) - sum(val_holidays)}\")\n",
        "    print(f\"  Average actual sales: {np.mean(val_actuals):.2f}\")\n",
        "    print(f\"  Average predicted sales: {np.mean(val_predictions):.2f}\")\n",
        "\n",
        "    return wmae\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    wmae = fast_optimized_arima_forecasting()\n",
        "    print(f\"\\n🎉 Final WMAE Score: {wmae:.2f}\")\n",
        "    if wmae < 2000:\n",
        "        print(\"🎯 SUCCESS! WMAE is below 2000!\")\n",
        "    else:\n",
        "        print(\"📈 Close! Try running again or further optimizations needed.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rZ_-z7GxYBvF",
        "outputId": "f8269930-0b73-4b94-9163-9642ef45cb0e"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "FAST OPTIMIZED ARIMA FORECASTING\n",
            "============================================================\n",
            "Loading data...\n",
            "Creating validation split...\n",
            "Training period: 2010-02-05 00:00:00 to 2012-07-27 00:00:00\n",
            "Validation period: 2012-08-03 00:00:00 to 2012-10-26 00:00:00\n",
            "Holiday multiplier: 1.074\n",
            "Creating fast optimized forecasts...\n",
            "Processing 3101 store-dept combinations...\n",
            "Processing combination 1/3101\n",
            "Processing combination 11/3101\n",
            "Processing combination 21/3101\n",
            "Processing combination 31/3101\n",
            "Processing combination 41/3101\n",
            "Processing combination 51/3101\n",
            "Processing combination 61/3101\n",
            "Processing combination 71/3101\n",
            "Processing combination 81/3101\n",
            "Processing combination 91/3101\n",
            "Processing combination 101/3101\n",
            "Processing combination 111/3101\n",
            "Processing combination 121/3101\n",
            "Processing combination 131/3101\n",
            "Processing combination 141/3101\n",
            "Processing combination 151/3101\n",
            "Processing combination 161/3101\n",
            "Processing combination 171/3101\n",
            "Processing combination 181/3101\n",
            "Processing combination 191/3101\n",
            "Processing combination 201/3101\n",
            "Processing combination 211/3101\n",
            "Processing combination 221/3101\n",
            "Processing combination 231/3101\n",
            "Processing combination 241/3101\n",
            "Processing combination 251/3101\n",
            "Processing combination 261/3101\n",
            "Processing combination 271/3101\n",
            "Processing combination 281/3101\n",
            "Processing combination 291/3101\n",
            "Processing combination 301/3101\n",
            "Processing combination 311/3101\n",
            "Processing combination 321/3101\n",
            "Processing combination 331/3101\n",
            "Processing combination 341/3101\n",
            "Processing combination 351/3101\n",
            "Processing combination 361/3101\n",
            "Processing combination 371/3101\n",
            "Processing combination 381/3101\n",
            "Processing combination 391/3101\n",
            "Processing combination 401/3101\n",
            "Processing combination 411/3101\n",
            "Processing combination 421/3101\n",
            "Processing combination 431/3101\n",
            "Processing combination 441/3101\n",
            "Processing combination 451/3101\n",
            "Processing combination 461/3101\n",
            "Processing combination 471/3101\n",
            "Processing combination 481/3101\n",
            "Processing combination 491/3101\n",
            "Processing combination 501/3101\n",
            "Processing combination 511/3101\n",
            "Processing combination 521/3101\n",
            "Processing combination 531/3101\n",
            "Processing combination 541/3101\n",
            "Processing combination 551/3101\n",
            "Processing combination 561/3101\n",
            "Processing combination 571/3101\n",
            "Processing combination 581/3101\n",
            "Processing combination 591/3101\n",
            "Processing combination 601/3101\n",
            "Processing combination 611/3101\n",
            "Processing combination 621/3101\n",
            "Processing combination 631/3101\n",
            "Processing combination 641/3101\n",
            "Processing combination 651/3101\n",
            "Processing combination 661/3101\n",
            "Processing combination 671/3101\n",
            "Processing combination 681/3101\n",
            "Processing combination 691/3101\n",
            "Processing combination 701/3101\n",
            "Processing combination 711/3101\n",
            "Processing combination 721/3101\n",
            "Processing combination 731/3101\n",
            "Processing combination 741/3101\n",
            "Processing combination 751/3101\n",
            "Processing combination 761/3101\n",
            "Processing combination 771/3101\n",
            "Processing combination 781/3101\n",
            "Processing combination 791/3101\n",
            "Processing combination 801/3101\n",
            "Processing combination 811/3101\n",
            "Processing combination 821/3101\n",
            "Processing combination 831/3101\n",
            "Processing combination 841/3101\n",
            "Processing combination 851/3101\n",
            "Processing combination 861/3101\n",
            "Processing combination 871/3101\n",
            "Processing combination 881/3101\n",
            "Processing combination 891/3101\n",
            "Processing combination 901/3101\n",
            "Processing combination 911/3101\n",
            "Processing combination 921/3101\n",
            "Processing combination 931/3101\n",
            "Processing combination 941/3101\n",
            "Processing combination 951/3101\n",
            "Processing combination 961/3101\n",
            "Processing combination 971/3101\n",
            "Processing combination 981/3101\n",
            "Processing combination 991/3101\n",
            "Processing combination 1001/3101\n",
            "Processing combination 1011/3101\n",
            "Processing combination 1021/3101\n",
            "Processing combination 1031/3101\n",
            "Processing combination 1041/3101\n",
            "Processing combination 1051/3101\n",
            "Processing combination 1061/3101\n",
            "Processing combination 1071/3101\n",
            "Processing combination 1081/3101\n",
            "Processing combination 1091/3101\n",
            "Processing combination 1101/3101\n",
            "Processing combination 1111/3101\n",
            "Processing combination 1121/3101\n",
            "Processing combination 1131/3101\n",
            "Processing combination 1141/3101\n",
            "Processing combination 1151/3101\n",
            "Processing combination 1161/3101\n",
            "Processing combination 1171/3101\n",
            "Processing combination 1181/3101\n",
            "Processing combination 1191/3101\n",
            "Processing combination 1201/3101\n",
            "Processing combination 1211/3101\n",
            "Processing combination 1221/3101\n",
            "Processing combination 1231/3101\n",
            "Processing combination 1241/3101\n",
            "Processing combination 1251/3101\n",
            "Processing combination 1261/3101\n",
            "Processing combination 1271/3101\n",
            "Processing combination 1281/3101\n",
            "Processing combination 1291/3101\n",
            "Processing combination 1301/3101\n",
            "Processing combination 1311/3101\n",
            "Processing combination 1321/3101\n",
            "Processing combination 1331/3101\n",
            "Processing combination 1341/3101\n",
            "Processing combination 1351/3101\n",
            "Processing combination 1361/3101\n",
            "Processing combination 1371/3101\n",
            "Processing combination 1381/3101\n",
            "Processing combination 1391/3101\n",
            "Processing combination 1401/3101\n",
            "Processing combination 1411/3101\n",
            "Processing combination 1421/3101\n",
            "Processing combination 1431/3101\n",
            "Processing combination 1441/3101\n",
            "Processing combination 1451/3101\n",
            "Processing combination 1461/3101\n",
            "Processing combination 1471/3101\n",
            "Processing combination 1481/3101\n",
            "Processing combination 1491/3101\n",
            "Processing combination 1501/3101\n",
            "Processing combination 1511/3101\n",
            "Processing combination 1521/3101\n",
            "Processing combination 1531/3101\n",
            "Processing combination 1541/3101\n",
            "Processing combination 1551/3101\n",
            "Processing combination 1561/3101\n",
            "Processing combination 1571/3101\n",
            "Processing combination 1581/3101\n",
            "Processing combination 1591/3101\n",
            "Processing combination 1601/3101\n",
            "Processing combination 1611/3101\n",
            "Processing combination 1621/3101\n",
            "Processing combination 1631/3101\n",
            "Processing combination 1641/3101\n",
            "Processing combination 1651/3101\n",
            "Processing combination 1661/3101\n",
            "Processing combination 1671/3101\n",
            "Processing combination 1681/3101\n",
            "Processing combination 1691/3101\n",
            "Processing combination 1701/3101\n",
            "Processing combination 1711/3101\n",
            "Processing combination 1721/3101\n",
            "Processing combination 1731/3101\n",
            "Processing combination 1741/3101\n",
            "Processing combination 1751/3101\n",
            "Processing combination 1761/3101\n",
            "Processing combination 1771/3101\n",
            "Processing combination 1781/3101\n",
            "Processing combination 1791/3101\n",
            "Processing combination 1801/3101\n",
            "Processing combination 1811/3101\n",
            "Processing combination 1821/3101\n",
            "Processing combination 1831/3101\n",
            "Processing combination 1841/3101\n",
            "Processing combination 1851/3101\n",
            "Processing combination 1861/3101\n",
            "Processing combination 1871/3101\n",
            "Processing combination 1881/3101\n",
            "Processing combination 1891/3101\n",
            "Processing combination 1901/3101\n",
            "Processing combination 1911/3101\n",
            "Processing combination 1921/3101\n",
            "Processing combination 1931/3101\n",
            "Processing combination 1941/3101\n",
            "Processing combination 1951/3101\n",
            "Processing combination 1961/3101\n",
            "Processing combination 1971/3101\n",
            "Processing combination 1981/3101\n",
            "Processing combination 1991/3101\n",
            "Processing combination 2001/3101\n",
            "Processing combination 2011/3101\n",
            "Processing combination 2021/3101\n",
            "Processing combination 2031/3101\n",
            "Processing combination 2041/3101\n",
            "Processing combination 2051/3101\n",
            "Processing combination 2061/3101\n",
            "Processing combination 2071/3101\n",
            "Processing combination 2081/3101\n",
            "Processing combination 2091/3101\n",
            "Processing combination 2101/3101\n",
            "Processing combination 2111/3101\n",
            "Processing combination 2121/3101\n",
            "Processing combination 2131/3101\n",
            "Processing combination 2141/3101\n",
            "Processing combination 2151/3101\n",
            "Processing combination 2161/3101\n",
            "Processing combination 2171/3101\n",
            "Processing combination 2181/3101\n",
            "Processing combination 2191/3101\n",
            "Processing combination 2201/3101\n",
            "Processing combination 2211/3101\n",
            "Processing combination 2221/3101\n",
            "Processing combination 2231/3101\n",
            "Processing combination 2241/3101\n",
            "Processing combination 2251/3101\n",
            "Processing combination 2261/3101\n",
            "Processing combination 2271/3101\n",
            "Processing combination 2281/3101\n",
            "Processing combination 2291/3101\n",
            "Processing combination 2301/3101\n",
            "Processing combination 2311/3101\n",
            "Processing combination 2321/3101\n",
            "Processing combination 2331/3101\n",
            "Processing combination 2341/3101\n",
            "Processing combination 2351/3101\n",
            "Processing combination 2361/3101\n",
            "Processing combination 2371/3101\n",
            "Processing combination 2381/3101\n",
            "Processing combination 2391/3101\n",
            "Processing combination 2401/3101\n",
            "Processing combination 2411/3101\n",
            "Processing combination 2421/3101\n",
            "Processing combination 2431/3101\n",
            "Processing combination 2441/3101\n",
            "Processing combination 2451/3101\n",
            "Processing combination 2461/3101\n",
            "Processing combination 2471/3101\n",
            "Processing combination 2481/3101\n",
            "Processing combination 2491/3101\n",
            "Processing combination 2501/3101\n",
            "Processing combination 2511/3101\n",
            "Processing combination 2521/3101\n",
            "Processing combination 2531/3101\n",
            "Processing combination 2541/3101\n",
            "Processing combination 2551/3101\n",
            "Processing combination 2561/3101\n",
            "Processing combination 2571/3101\n",
            "Processing combination 2581/3101\n",
            "Processing combination 2591/3101\n",
            "Processing combination 2601/3101\n",
            "Processing combination 2611/3101\n",
            "Processing combination 2621/3101\n",
            "Processing combination 2631/3101\n",
            "Processing combination 2641/3101\n",
            "Processing combination 2651/3101\n",
            "Processing combination 2661/3101\n",
            "Processing combination 2671/3101\n",
            "Processing combination 2681/3101\n",
            "Processing combination 2691/3101\n",
            "Processing combination 2701/3101\n",
            "Processing combination 2711/3101\n",
            "Processing combination 2721/3101\n",
            "Processing combination 2731/3101\n",
            "Processing combination 2741/3101\n",
            "Processing combination 2751/3101\n",
            "Processing combination 2761/3101\n",
            "Processing combination 2771/3101\n",
            "Processing combination 2781/3101\n",
            "Processing combination 2791/3101\n",
            "Processing combination 2801/3101\n",
            "Processing combination 2811/3101\n",
            "Processing combination 2821/3101\n",
            "Processing combination 2831/3101\n",
            "Processing combination 2841/3101\n",
            "Processing combination 2851/3101\n",
            "Processing combination 2861/3101\n",
            "Processing combination 2871/3101\n",
            "Processing combination 2881/3101\n",
            "Processing combination 2891/3101\n",
            "Processing combination 2901/3101\n",
            "Processing combination 2911/3101\n",
            "Processing combination 2921/3101\n",
            "Processing combination 2931/3101\n",
            "Processing combination 2941/3101\n",
            "Processing combination 2951/3101\n",
            "Processing combination 2961/3101\n",
            "Processing combination 2971/3101\n",
            "Processing combination 2981/3101\n",
            "Processing combination 2991/3101\n",
            "Processing combination 3001/3101\n",
            "Processing combination 3011/3101\n",
            "Processing combination 3021/3101\n",
            "Processing combination 3031/3101\n",
            "Processing combination 3041/3101\n",
            "Processing combination 3051/3101\n",
            "Processing combination 3061/3101\n",
            "Processing combination 3071/3101\n",
            "Processing combination 3081/3101\n",
            "Processing combination 3091/3101\n",
            "Processing combination 3101/3101\n",
            "✅ Fast Optimized ARIMA Local Validation WMAE: 2152.64\n",
            "\n",
            "Validation Statistics:\n",
            "  Total validation rows: 38530\n",
            "  Holiday rows: 2966\n",
            "  Non-holiday rows: 35564\n",
            "  Average actual sales: 15620.50\n",
            "  Average predicted sales: 15957.12\n",
            "\n",
            "🎉 Final WMAE Score: 2152.64\n",
            "📈 Close! Try running again or further optimizations needed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FIodmSM7hyqa"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}